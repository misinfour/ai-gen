name: 文章生成工作流

on:
  schedule:
    # 每天北京时间1点执行 (UTC时间17点)
    # 每日发布模式：随机分配文章到各个网站
    - cron: '30 20 20 10 *'
  workflow_dispatch:
    inputs:
      need_images:
        description: '是否需要下载图片'
        required: false
        type: boolean
        default: true
      articles_per_site:
        description: '每个网站发布文章数量（可选，默认使用配置文件设置）'
        required: false
        type: string
      max_workers:
        description: '并行生成线程数（可选，默认6个）'
        required: false
        type: string
        default: '6'
      batch_size:
        description: '批处理大小（可选，默认6个[指足够6篇才提交]）'
        required: false
        type: string
        default: '6'

jobs:
  generate-articles:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # 设置2小时超时
    permissions:
      contents: write
      pull-requests: write
      actions: write
    
    steps:
    - name: 检出代码
      uses: actions/checkout@v4
      with:
        persist-credentials: true
        token: ${{ secrets.GH_PAT }}  # 直接使用 PAT，去掉回退逻辑
      
    - name: 设置Python环境
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: 安装依赖
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: 从远程获取配置文件
      run: |
        echo "📥 正在从远程获取配置文件..."
        curl -s "https://eternity.misinguo.com/ai-gen/config.json" -o config.json
        
        # 检查是否成功获取配置文件
        if [ -f "config.json" ] && [ -s "config.json" ]; then
          echo "✅ 成功获取远程配置文件"
          echo "📊 配置文件大小: $(wc -c < config.json) 字节"
        else
          echo "❌ 获取远程配置文件失败"
          exit 1
        fi
        
    - name: 创建配置文件（备用）
      run: |
        # 只有在config.json不存在时才创建配置文件（作为备用方案）
        if [ ! -f "config.json" ]; then
          echo "⚠️ config.json不存在，使用备用配置文件..."
          cat > config.json << EOF
        {
          "default_platform": "groq",
          "platforms": {
            "groq": {
              "name": "Groq",
              "base_url": "https://api.groq.com/openai/v1/chat/completions",
              "proxy_url": "https://m3u8-player.5yxy5.com/api/forward/https://api.groq.com/openai/v1/chat/completions",
              "models": {
                "default": "deepseek-r1-distill-llama-70b",
                "available": [
                  "deepseek-r1-distill-llama-70b",
                  "llama-3.1-70b-versatile",
                  "llama-3.1-8b-instant",
                  "mixtral-8x7b-32768"
                ]
              },
              "api_keys": [
                "${{ secrets.GROQ_API_KEY_1 }}",
                "${{ secrets.GROQ_API_KEY_2 }}",
                "${{ secrets.GROQ_API_KEY_3 }}",
                "${{ secrets.GROQ_API_KEY_4 }}",
                "${{ secrets.GROQ_API_KEY_5 }}",
                "${{ secrets.GROQ_API_KEY_6 }}"
              ],
              "headers": {
                "Content-Type": "application/json"
              },
              "auth_type": "bearer",
              "timeout": 60,
              "max_retries": 20
            },
            "openai": {
              "name": "OpenAI",
              "base_url": "https://api.openai.com/v1/chat/completions",
              "proxy_url": "https://m3u8-player.5yxy5.com/api/forward/https://api.openai.com/v1/chat/completions",
              "models": {
                "default": "gpt-3.5-turbo",
                "available": [
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-16k",
                  "gpt-4",
                  "gpt-4-turbo",
                  "gpt-4o",
                  "gpt-4o-mini"
                ]
              },
              "api_keys": [
                "${{ secrets.OPENAI_API_KEY }}"
              ],
              "headers": {
                "Content-Type": "application/json"
              },
              "auth_type": "bearer",
              "timeout": 60,
              "max_retries": 20
            },
            "gemini": {
              "name": "Google Gemini",
              "base_url": "https://generativelanguage.googleapis.com/v1beta/models",
              "proxy_url": "https://m3u8-player.5yxy5.com/api/forward/https://generativelanguage.googleapis.com/v1beta/models",
              "models": {
                "default": "gemini-1.5-flash",
                "available": [
                  "gemini-1.5-flash",
                  "gemini-1.5-pro",
                  "gemini-1.0-pro"
                ]
              },
              "api_keys": [
                "${{ secrets.GEMINI_API_KEY }}"
              ],
              "headers": {
                "Content-Type": "application/json"
              },
              "auth_type": "api_key",
              "timeout": 60,
              "max_retries": 20
            },
            "claude": {
              "name": "Anthropic Claude",
              "base_url": "https://api.anthropic.com/v1/messages",
              "proxy_url": "https://m3u8-player.5yxy5.com/api/forward/https://api.anthropic.com/v1/messages",
              "models": {
                "default": "claude-3-sonnet-20240229",
                "available": [
                  "claude-3-sonnet-20240229",
                  "claude-3-opus-20240229",
                  "claude-3-haiku-20240307"
                ]
              },
              "api_keys": [
                "${{ secrets.CLAUDE_API_KEY }}"
              ],
              "headers": {
                "Content-Type": "application/json",
                "anthropic-version": "2023-06-01"
              },
              "auth_type": "x-api-key",
              "timeout": 60,
              "max_retries": 20
            }
          },
          "settings": {
            "use_proxy": true,
            "temperature": 0.6,
            "max_tokens": 10000,
            "top_p": 0.95,
            "stream": false
          },
          "kv_storage": {
            "account_id": "${{ secrets.CLOUDFLARE_ACCOUNT_ID }}",
            "namespace_id": "${{ secrets.CLOUDFLARE_NAMESPACE_ID }}",
            "api_token": "${{ secrets.CLOUDFLARE_API_TOKEN }}"
          },
          "prompts": {
            "zh-cn": {
              "name": "简体中文提示词",
              "template": "${{ secrets.ZH_CN_PROMPT_TEMPLATE }}"
            },
            "zh-tw": {
              "name": "繁體中文提示詞",
              "template": "${{ secrets.ZH_TW_PROMPT_TEMPLATE }}"
            }
          },
          "google_seo_article_title_prompt": {
            "zh-cn": {
              "name": "简体中文提示词",
              "template": "${{ secrets.GOOGLE_SEO_ARTICLE_TITLE_PROMPT_ZH_CN }}"
            },
            "zh-tw": {
              "name": "繁體中文提示詞",
              "template": "${{ secrets.GOOGLE_SEO_ARTICLE_TITLE_PROMPT_ZH_TW }}"
            }
          }
        }
        EOF
        else
          echo "config.json已存在，跳过创建配置文件"
        fi
        
    - name: 创建必要的目录
      run: |
        # 获取当前日期（使用北京时间）
        # 设置时区为北京时间
        export TZ='Asia/Shanghai'
        YEAR=$(date +%Y)
        MONTH=$(date +%m)
        DAY=$(date +%d)
        
        # 创建按日期组织的目录结构
        mkdir -p logs/$YEAR/$MONTH/$DAY/zh-cn
        mkdir -p logs/$YEAR/$MONTH/$DAY/zh-tw
        mkdir -p logs/$YEAR/$MONTH/$DAY/images
        
        echo "📁 创建目录结构: logs/$YEAR/$MONTH/$DAY/ (北京时间)"
        
    - name: 检查配置文件
      run: |
        if [ ! -f "config.json" ]; then
          echo "❌ 配置文件 config.json 不存在"
          exit 1
        fi
        echo "✅ 配置文件存在"
        
    - name: 检查长尾词文件
      run: |
        if [ ! -f "长尾词.txt" ]; then
          echo "❌ 长尾词文件 长尾词.txt 不存在"
          exit 1
        fi
        echo "✅ 长尾词文件存在"
        
    - name: 运行文章生成任务
      id: generate-task
      run: |
        # 设置环境变量
        export PYTHONUNBUFFERED=1
        # 记录开始时间与超时阈值，用于区分超时 vs 手动取消
        START_TS=$(date +%s)
        TIMEOUT_MINUTES=120
        # 在接收到终止信号时进行判断：接近超时时认为是超时取消，否则认为是手动取消
        trap 'NOW=$(date +%s); ELAPSED=$(( NOW - START_TS )); THRESH=$(( TIMEOUT_MINUTES*60 - 300 )); echo "⚠️ 收到终止信号，已运行 ${ELAPSED}s，阈值 ${THRESH}s"; if [ "$ELAPSED" -ge "$THRESH" ]; then echo "⏰ 推测为接近超时导致的取消，标记为需重试"; printf "{\"status\":\"timeout\",\"timestamp\":\"%s\"}\n" "$(date -Iseconds)" > generate_result.json; touch .timeout_inferred; else echo "🛑 推测为手动取消，不重试"; printf "{\"status\":\"cancelled\",\"timestamp\":\"%s\"}\n" "$(date -Iseconds)" > generate_result.json; fi; exit 1' SIGTERM SIGINT
        
        # 获取处理参数
        NEED_IMAGES="${{ github.event.inputs.need_images || 'true' }}"
        ARTICLES_PER_SITE="${{ github.event.inputs.articles_per_site }}"
        MAX_WORKERS="${{ github.event.inputs.max_workers || '6' }}"
        BATCH_SIZE="${{ github.event.inputs.batch_size || '6' }}"
        
        echo "🚀 开始执行文章生成任务..."
        echo "需要图片: ${NEED_IMAGES}"
        echo "每站文章数: ${ARTICLES_PER_SITE:-'使用默认值'}"
        echo "并行线程数: ${MAX_WORKERS}"
        echo "批处理大小: ${BATCH_SIZE}"
        echo "触发方式: ${{ github.event_name }}"
        echo "运行时间: $(date)"
        
        # 运行文章生成脚本
        python -c "
        import sys
        sys.path.append('.')
        
        # 导入必要的模块
        from process_articles import daily_publish_articles
        import json
        from datetime import datetime
        
        try:
            # 解析参数
            need_images = '$NEED_IMAGES'
            articles_per_site = '$ARTICLES_PER_SITE'
            max_workers = '$MAX_WORKERS'
            batch_size = '$BATCH_SIZE'
            
            # 转换参数类型
            need_images_bool = need_images.lower() == 'true' if need_images else True
            articles_per_site_int = None
            max_workers_int = None
            batch_size_int = None
            
            if articles_per_site and articles_per_site.strip():
                try:
                    articles_per_site_int = int(articles_per_site)
                    print(f'解析到 articles_per_site: {articles_per_site_int}')
                except ValueError:
                    print(f'警告: 无法将 {articles_per_site} 转换为整数，使用默认值 None')
            
            if max_workers and max_workers.strip():
                try:
                    max_workers_int = int(max_workers)
                    print(f'解析到 max_workers: {max_workers_int}')
                except ValueError:
                    print(f'警告: 无法将 {max_workers} 转换为整数，使用默认值 None')
            
            if batch_size and batch_size.strip():
                try:
                    batch_size_int = int(batch_size)
                    print(f'解析到 batch_size: {batch_size_int}')
                except ValueError:
                    print(f'警告: 无法将 {batch_size} 转换为整数，使用默认值 None')
            
            print('📅 使用每日发布模式：随机抽取可发布标题并随机分配到网站')
            print(f'📊 发布策略：需要下载图片={need_images_bool}')
            if articles_per_site_int:
                print(f'📊 发布策略：每个网站发布 {articles_per_site_int} 篇文章（使用工作流指定数量）')
            else:
                print('📊 发布策略：每个网站发布默认数量（参考配置文件）')
            
            if max_workers_int:
                print(f'🔧 并行配置：使用 {max_workers_int} 个线程（工作流指定）')
            else:
                print('🔧 并行配置：使用默认线程数（参考配置文件）')
                
            if batch_size_int:
                print(f'🔧 并行配置：批处理大小 {batch_size_int}（工作流指定）')
            else:
                print('🔧 并行配置：使用默认批处理大小（参考配置文件）')
            
            # 运行每日发布
            result = daily_publish_articles(
                need_images=need_images_bool, 
                articles_per_site=articles_per_site_int,
                max_workers=max_workers_int,
                batch_size=batch_size_int
            )
            
            if result is True:
                print('✅ 文章生成完成')
                
                # 设置成功状态
                with open('generate_result.json', 'w', encoding='utf-8') as f:
                    json.dump({
                        'status': 'success',
                        'timestamp': datetime.now().isoformat(),
                        'need_images': need_images_bool,
                        'articles_per_site': articles_per_site_int
                    }, f, ensure_ascii=False, indent=2)
            elif result == 'circuit_breaker':
                print('⚠️ 文章生成触发熔断机制（API服务异常）')
                
                # 熔断状态
                with open('generate_result.json', 'w', encoding='utf-8') as f:
                    json.dump({
                        'status': 'circuit_breaker',
                        'message': '文章生成触发熔断机制，API服务异常，需要等待后重试',
                        'timestamp': datetime.now().isoformat(),
                        'need_images': need_images_bool,
                        'articles_per_site': articles_per_site_int
                    }, f, ensure_ascii=False, indent=2)
                
                # 抛出异常以触发重试模式
                raise Exception('文章生成触发熔断机制，需要等待后重试')
            else:
                print('⚠️ 文章生成失败')
                
                # 设置失败状态
                with open('generate_result.json', 'w', encoding='utf-8') as f:
                    json.dump({
                        'status': 'error',
                        'error': '文章生成失败',
                        'timestamp': datetime.now().isoformat(),
                        'need_images': need_images_bool,
                        'articles_per_site': articles_per_site_int
                    }, f, ensure_ascii=False, indent=2)
                
                # 抛出异常以触发重试
                raise Exception('文章生成失败')
                
        except Exception as e:
            print(f'❌ 文章生成失败: {str(e)}')
            
            # 检查是否是熔断相关的异常
            error_str = str(e)
            # 扩展熔断检测条件，包括更多网络和API服务异常
            circuit_breaker_keywords = [
                '熔断机制', 'HTTP错误 500', 'ApiExhaustedRetriesError',
                'Internal Server Error', 'Server Error', '500 Server Error',
                'internal server error', 'Connection timeout', 'Read timeout',
                'Connection error', 'Network error', 'Service unavailable',
                'Bad Gateway', 'Gateway Timeout', 'HTTP错误 502', 'HTTP错误 503', 'HTTP错误 504',
                '所有重试都失败了', '连续失败', 'API服务异常', 'chat_completion',
                'API重试耗尽异常', 'API服务连续失败', '达到最大重试次数', '🔥', '⛔',
                '所有API密钥都失败', '重试超过上限'
            ]
            
            is_circuit_breaker = any(keyword in error_str for keyword in circuit_breaker_keywords)
            
            if is_circuit_breaker:
                # 设置熔断状态
                with open('generate_result.json', 'w', encoding='utf-8') as f:
                    json.dump({
                        'status': 'circuit_breaker',
                        'message': '文章生成触发熔断机制，API服务异常，需要等待后重试',
                        'error': error_str,
                        'timestamp': datetime.now().isoformat(),
                        'need_images': need_images,
                        'articles_per_site': articles_per_site
                    }, f, ensure_ascii=False, indent=2)
            else:
                # 设置普通失败状态
                with open('generate_result.json', 'w', encoding='utf-8') as f:
                    json.dump({
                        'status': 'error',
                        'error': error_str,
                        'timestamp': datetime.now().isoformat(),
                        'need_images': need_images,
                        'articles_per_site': articles_per_site
                    }, f, ensure_ascii=False, indent=2)
            
            # 重新抛出异常以触发重试
            raise
        "
        
    - name: 检查处理结果
      id: check-result
      if: always()
      run: |
        if [ -f "generate_result.json" ]; then
          STATUS=$(python -c "import json; data=json.load(open('generate_result.json')); print(data['status'])")
          echo "处理状态: $STATUS"
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          
          if [ "$STATUS" = "error" ]; then
            ERROR_MSG=$(python -c "import json; data=json.load(open('generate_result.json')); print(data.get('error', 'Unknown error'))")
            echo "错误信息: $ERROR_MSG"
            echo "error_message=$ERROR_MSG" >> $GITHUB_OUTPUT
          elif [ "$STATUS" = "circuit_breaker" ]; then
            CIRCUIT_MSG=$(python -c "import json; data=json.load(open('generate_result.json')); print(data.get('message', 'Circuit breaker triggered'))")
            echo "熔断信息: $CIRCUIT_MSG"
            echo "error_message=$CIRCUIT_MSG" >> $GITHUB_OUTPUT
          fi
        else
          echo "未找到处理结果文件"
          echo "status=unknown" >> $GITHUB_OUTPUT
        fi
        
    - name: 上传生成的文章
      id: upload-artifacts
      uses: actions/upload-artifact@v4
      if: always()
      continue-on-error: true
      with:
        name: generated-articles-${{ github.run_number }}
        path: |
          generate_result.json
          *.log
        retention-days: 7
        compression-level: 1
        
    - name: 上传错误日志
      uses: actions/upload-artifact@v4
      if: failure()
      continue-on-error: true
      with:
        name: error-logs-${{ github.run_number }}
        path: logs/*/error_log.txt
        retention-days: 3
        compression-level: 1
        
    - name: 处理Artifact存储配额错误
      if: always()
      run: |
        echo "📊 检查Artifact上传状态..."
        if [ "${{ steps.upload-artifacts.outcome }}" = "failure" ]; then
          echo "⚠️ Artifact上传失败，但这不影响任务执行结果"
          echo "注意：Artifact存储配额错误不会影响工作流的成功执行"
          echo "文章生成和提交到仓库的功能仍然正常工作"
        else
          echo "✅ Artifact上传成功"
        fi
        
        # 清理旧的日志文件以减少存储使用
        echo "🧹 清理旧的日志文件..."
        find logs -name "*.log" -mtime +1 -delete 2>/dev/null || true
        find logs -name "error_log.txt" -mtime +7 -delete 2>/dev/null || true
        
    - name: 清理不完整的文章目录和临时下载文件夹
      if: always()
      run: |
        echo "🧹 清理没有README.md文件的不完整文章目录..."
        
        # 查找所有没有README.md文件的文章目录并删除
        find logs/backup -type d -name "images" | while read images_dir; do
          article_dir=$(dirname "$images_dir")
          if [ ! -f "$article_dir/README.md" ]; then
            echo "🗑️  删除不完整的文章目录: $article_dir"
            rm -rf "$article_dir"
          fi
        done
        
        # 清理空的日期目录
        find logs/backup -type d -empty -delete 2>/dev/null || true
        
        echo "🧹 清理临时下载文件夹..."
        
        # 查找并删除所有临时下载文件夹
        find logs -type d -name "temp_download" | while read temp_dir; do
          echo "🗑️  删除临时下载文件夹: $temp_dir"
          rm -rf "$temp_dir"
        done
        
        # 查找并删除所有以关键词命名的下载文件夹（bing-image-downloader创建的）
        find logs -type d -name "*" | while read dir; do
          # 检查是否是下载文件夹（包含图片文件但没有README.md）
          if [ -d "$dir" ] && [ ! -f "$dir/README.md" ] && [ ! -f "$(dirname "$dir")/README.md" ]; then
            # 检查是否包含图片文件
            if find "$dir" -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -o -name "*.gif" -o -name "*.webp" | head -1 | grep -q .; then
              echo "🗑️  删除临时下载文件夹: $dir"
              rm -rf "$dir"
            fi
          fi
        done
        
        echo "✅ 清理完成"
        
    - name: 提交生成的文章到仓库
      if: always()
      run: |
        # 配置Git用户信息
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # 先拉取远程更改，避免推送冲突
        echo "🔄 拉取远程更改..."
        git pull origin main --no-edit || {
          echo "⚠️ 拉取失败，尝试强制拉取..."
          git fetch origin main
          git reset --hard origin/main
        }
        
        # 检查logs目录是否存在，如果存在则添加生成的文章
        if [ -d "logs" ] && [ "$(find logs -type f -name "*.md" | wc -l)" -gt 0 ]; then
          echo "📁 发现生成的文章，添加到Git..."
          git add logs/
        else
          echo "📁 没有发现新的文章文件，跳过Git添加"
        fi
        
        # 检查是否有变更
        if git diff --staged --quiet; then
          echo "没有新的文章生成"
        else
          # 提交变更
          git commit -m "🤖 自动生成文章 - 工作流 #${{ github.run_number }} [skip ci]"
          
          # 推送到仓库，使用重试机制
          echo "📤 推送文章到仓库..."
          for i in {1..3}; do
            if git push origin main; then
              echo "✅ 文章已成功提交到仓库"
              break
            else
              echo "⚠️ 推送失败，尝试第 $i 次重试..."
              sleep 5
              # 重新拉取并合并
              git pull origin main --no-edit || git reset --hard origin/main
            fi
          done
        fi
        
    - name: 检查生成结果
      run: |
        echo "📊 检查生成结果..."
        
        # 统计生成的文件数量
        ARTICLE_COUNT=$(find logs -name "README.md" -type f | wc -l)
        echo "生成的文章数量: $ARTICLE_COUNT"
        
        # 检查错误日志
        ERROR_LOG_FOUND=false
        for error_log in logs/*/error_log.txt; do
          if [ -f "$error_log" ]; then
            ERROR_COUNT=$(wc -l < "$error_log")
            echo "错误记录数量: $ERROR_COUNT (来自 $error_log)"
            ERROR_LOG_FOUND=true
          fi
        done
        
        if [ "$ERROR_LOG_FOUND" = false ]; then
          echo "没有错误记录"
        fi
        
        # 输出文件结构
        echo "📁 生成的文件结构:"
        find logs -type f -name "*.md" | head -10
        
    - name: 输出完成信息
      if: always()
      run: |
        echo "📝 文章生成任务完成"
        echo "🕐 执行时间: $(date)"
        echo "📊 生成文章数量: $ARTICLE_COUNT"
        echo "❌ 错误数量: $ERROR_COUNT"
        echo "🔗 工作流链接: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        
    - name: 处理成功 - 恢复日常模式
      if: steps.check-result.outputs.status == 'success'
      run: |
        echo "✅ 文章生成成功完成！"
        echo "🔄 恢复工作流为日常模式..."
        
        # 运行脚本恢复工作流为日常模式
        python update_workflow_schedule.py --type daily --workflow generate-articles --no-push
        
        echo "✅ 工作流已恢复为日常模式"
        
    - name: 推送恢复日常模式的工作流文件
      if: steps.check-result.outputs.status == 'success'
      run: |
        echo "📤 推送恢复日常模式的工作流文件..."
        
        # 配置Git用户信息
        git config user.name "github-actions"
        git config user.email "github-actions@users.noreply.github.com"
        
        # 先拉取远程更改，避免推送冲突
        echo "🔄 拉取远程更改..."
        git pull origin main --no-edit || {
          echo "⚠️ 拉取失败，尝试强制拉取..."
          git fetch origin main
          git reset --hard origin/main
        }
        
        # 添加工作流文件
        git add .github/workflows/generate-articles.yml
        
        # 检查是否有变更
        if git diff --staged --quiet; then
          echo "📝 工作流文件未更改"
        else
          # 提交变更
          git commit -m "恢复工作流为日常模式"
          
          # 推送到仓库，使用重试机制
          echo "📤 推送工作流文件到仓库..."
          for i in {1..3}; do
            if git push https://${{ secrets.USERNAME }}:${{ secrets.GH_PAT }}@github.com/${{ github.repository }}.git HEAD:main; then
              echo "✅ 工作流文件已成功推送"
              break
            else
              echo "⚠️ 推送失败，尝试第 $i 次重试..."
              sleep 5
              # 重新拉取并合并
              git pull origin main --no-edit || git reset --hard origin/main
            fi
          done
        fi
        
    - name: 处理失败 - 更新工作流为重试模式并推送
      if: always() && (steps.check-result.outputs.status == 'error' || steps.check-result.outputs.status == 'circuit_breaker' || steps.check-result.outputs.status == 'timeout' || (steps.check-result.outputs.status == 'unknown' && steps.generate-task.outcome == 'failure')) && steps.check-result.outputs.status != 'cancelled'
      run: |
        echo "⚠️ 文章生成任务执行失败！"
        echo "🔄 调整工作流为重试模式（30分钟后重试）..."
        
        # 配置Git用户信息
        git config user.name "github-actions"
        git config user.email "github-actions@users.noreply.github.com"
        
        # 先拉取远程更改，避免推送冲突
        echo "🔄 拉取远程更改..."
        git pull origin main --no-edit || {
          echo "⚠️ 拉取失败，尝试强制拉取..."
          git fetch origin main
          git reset --hard origin/main
        }
        
        # 运行脚本更新工作流文件
        echo "🔧 更新工作流文件为重试模式..."
        python update_workflow_schedule.py --type retry --delay 30 --workflow generate-articles --no-push
        
        # 添加工作流文件
        git add .github/workflows/generate-articles.yml
        
        # 检查是否有变更
        if git diff --staged --quiet; then
          echo "📝 工作流文件未更改，可能已经是最新状态"
        else
          # 提交变更
          git commit -m "自动调整工作流为重试模式 (30分钟后重试)"
          
          # 推送到仓库，使用重试机制
          echo "📤 推送工作流文件到仓库..."
          for i in {1..3}; do
            if git push https://${{ secrets.USERNAME }}:${{ secrets.GH_PAT }}@github.com/${{ github.repository }}.git HEAD:main; then
              echo "✅ 工作流文件已成功推送"
              break
            else
              echo "⚠️ 推送失败，尝试第 $i 次重试..."
              sleep 5
              # 重新拉取并合并
              git pull origin main --no-edit || git reset --hard origin/main
            fi
          done
        fi
        
        echo "✅ 重试模式设置完成"
        
    - name: 发送成功通知
      if: steps.check-result.outputs.status == 'success'
      run: |
        echo "🎉 文章生成成功完成！"
        echo "运行编号: ${{ github.run_number }}"
        echo "完成时间: $(date)"
        echo "需要图片: ${{ github.event.inputs.need_images || 'true' }}"
        echo "每站文章数: ${{ github.event.inputs.articles_per_site || '使用默认值' }}"
        echo "✅ 工作流已自动恢复为日常模式"
        
    - name: 处理Artifact上传失败但任务成功的情况
      if: steps.check-result.outputs.status == 'success' && steps.upload-artifacts.outcome == 'failure'
      run: |
        echo "✅ 文章生成任务成功完成！"
        echo "⚠️ 但Artifact上传失败（存储配额问题）"
        echo "📊 这不会影响任务执行结果，工作流将正常恢复为日常模式"
        echo "🔄 工作流已自动恢复为日常模式"
        
    - name: 发送失败通知
      if: (steps.check-result.outputs.status == 'error' || steps.check-result.outputs.status == 'circuit_breaker' || steps.check-result.outputs.status == 'unknown') && steps.generate-task.outcome == 'failure'
      run: |
        if [ "${{ steps.check-result.outputs.status }}" = "circuit_breaker" ]; then
          echo "🔥 文章生成触发熔断机制！"
          echo "运行编号: ${{ github.run_number }}"
          echo "触发时间: $(date)"
          echo "熔断信息: ${{ steps.check-result.outputs.error_message }}"
          echo "🕐 已安排30分钟后重试"
        else
          echo "❌ 文章生成失败！"
          echo "运行编号: ${{ github.run_number }}"
          echo "失败时间: $(date)"
          echo "错误信息: ${{ steps.check-result.outputs.error_message }}"
          echo "🕐 已安排30分钟后重试"
        fi

    - name: 处理取消 - 不重试
      if: cancelled()
      run: |
        echo "⏰ 工作流被手动取消！"
        echo "运行编号: ${{ github.run_number }}"
        echo "取消时间: $(date)"
        echo "⚠️ 手动取消不会触发重试，工作流将保持当前状态"

    - name: 发送取消通知
      if: cancelled()
      run: |
        if [ -f ".timeout_inferred" ]; then
          echo "⏰ 工作流因接近超时而被取消（推测）！"
          echo "运行编号: ${{ github.run_number }}"
          echo "时间: $(date)"
          echo "🕐 将按照重试策略处理"
        else
          echo "⏰ 工作流被手动取消！"
          echo "运行编号: ${{ github.run_number }}"
          echo "取消时间: $(date)"
          echo "⚠️ 手动取消不会触发重试"
        fi

    - name: 处理超时取消 - 设置重试模式
      if: cancelled()
      run: |
        if [ -f ".timeout_inferred" ]; then
          echo "🔄 检测到超时取消（推测），更新工作流为重试模式（30分钟后重试）..."

          # 配置Git用户信息
          git config user.name "github-actions"
          git config user.email "github-actions@users.noreply.github.com"

          # 先拉取远程更改，避免推送冲突
          echo "🔄 拉取远程更改..."
          git pull origin main --no-edit || {
            echo "⚠️ 拉取失败，尝试强制拉取..."
            git fetch origin main
            git reset --hard origin/main
          }

          # 运行脚本更新工作流文件
          echo "🔧 更新工作流文件为重试模式..."
          python update_workflow_schedule.py --type retry --delay 30 --workflow generate-articles --no-push

          # 添加并提交工作流文件
          git add .github/workflows/generate-articles.yml
          if git diff --staged --quiet; then
            echo "📝 工作流文件未更改，可能已经是最新状态"
          else
            git commit -m "因超时取消推测，自动调整工作流为重试模式 (30分钟后重试)"
            echo "📤 推送工作流文件到仓库..."
            for i in {1..3}; do
              if git push https://${{ secrets.USERNAME }}:${{ secrets.GH_PAT }}@github.com/${{ github.repository }}.git HEAD:main; then
                echo "✅ 工作流文件已成功推送"
                break
              else
                echo "⚠️ 推送失败，尝试第 $i 次重试..."
                sleep 5
                git pull origin main --no-edit || git reset --hard origin/main
              fi
            done
          fi
          echo "✅ 已为超时取消设置重试模式"
        else
          echo "🛑 检测到手动取消，不设置重试模式"
        fi

