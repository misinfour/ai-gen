import json
from datetime import datetime, timezone, timedelta
from pathlib import Path
from kv_manager import kv_read, kv_write
from config_manager import ConfigManager
from article_generator import ArticleGenerator
from api_manager import MultiPlatformApiManager, ApiExhaustedRetriesError
from parallel_article_generator import ParallelArticleGenerator

# å®šä¹‰åŒ—äº¬æ—¶é—´æ—¶åŒº
beijing_tz = timezone(timedelta(hours=8))

class PublishManager:
    """å‘å¸ƒç®¡ç†å™¨ï¼Œè´Ÿè´£æŒ‰æ’åé¡ºåºå‘å¸ƒæ–‡ç« åˆ°ä¸åŒç½‘ç«™"""
    
    def __init__(self, config_manager=None):
        self.config_manager = config_manager or ConfigManager()
        self.api_manager = MultiPlatformApiManager(self.config_manager)
        self.article_generator = ArticleGenerator(self.config_manager, self.api_manager)
        
        # åˆå§‹åŒ–å¹¶è¡Œæ–‡ç« ç”Ÿæˆå™¨
        self.parallel_generator = ParallelArticleGenerator(self.config_manager, self.api_manager)
        
        # è·å–å‘å¸ƒé…ç½®
        self.publish_config = self.config_manager.config.get('daily_publish', {})
        self.enabled = self.publish_config.get('enabled', True)
        self.articles_per_site = self.publish_config.get('articles_per_site', 100)
        
        # åŠ¨æ€è®¡ç®—å¯ç”¨çš„Gitä»“åº“æ•°é‡
        enabled_repos = self.article_generator.repo_manager.get_enabled_repositories()
        git_repos = {k: v for k, v in enabled_repos.items() if v['type'] == 'git'}
        self.total_sites = len(git_repos)
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æŒ‡å®šäº†total_sitesä¸”å¤§äº0ï¼Œåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶çš„å€¼ï¼ˆå‘åå…¼å®¹ï¼‰
        config_total_sites = self.publish_config.get('total_sites', 0)
        if config_total_sites > 0:
            self.total_sites = config_total_sites
            print(f"âš ï¸  ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„total_sites={self.total_sites}ï¼Œå®é™…å¯ç”¨çš„Gitä»“åº“æ•°é‡ä¸º{len(git_repos)}")
        
        self.start_from_rank = self.publish_config.get('start_from_rank', 1)
        self.max_rank_search = self.publish_config.get('max_rank_search', 10000)
        
        # è·å–å¹¶è¡Œé…ç½®
        self.parallel_config = self.publish_config.get('parallel_generation', {})
        self.parallel_enabled = self.parallel_config.get('enabled', True)
        self.batch_size = self.parallel_config.get('batch_size', 4)
        
        # è·å–KVå­˜å‚¨é…ç½®
        kv_config = self.config_manager.config.get('kv_storage', {})
        self.account_id = kv_config.get('account_id')
        self.namespace_id = kv_config.get('namespace_id')
        self.api_token = kv_config.get('api_token')
        
        # è·å–ä»“åº“é…ç½®
        self.repositories = self.config_manager.config.get('repositories', {})
        
        print(f"ğŸ“‹ å‘å¸ƒç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"  - æ¯æ—¥å‘å¸ƒ: {'å¯ç”¨' if self.enabled else 'ç¦ç”¨'}")
        print(f"  - æ¯ä¸ªç½‘ç«™å‘å¸ƒæ•°é‡: {self.articles_per_site}")
        print(f"  - æ€»ç½‘ç«™æ•°é‡: {self.total_sites}")
        print(f"  - å¼€å§‹æ’å: {self.start_from_rank}")
        print(f"  - æœ€å¤§æœç´¢æ’å: {self.max_rank_search}")
        print(f"  - å¹¶è¡Œç”Ÿæˆ: {'å¯ç”¨' if self.parallel_enabled else 'ç¦ç”¨'}")
        if self.parallel_enabled:
            print(f"  - æ‰¹å¤„ç†å¤§å°: {self.batch_size}")
    
    def find_latest_kv_data(self, max_days_back=30):
        """æŸ¥æ‰¾KVå­˜å‚¨ä¸­æœ€æ–°å­˜åœ¨çš„æ•°æ®"""
        from datetime import timedelta
        
        current_date = datetime.now(beijing_tz)
        
        for i in range(max_days_back):
            check_date = current_date - timedelta(days=i)
            date_str = check_date.strftime('%Y-%m-%d')
            kv_key = f"qimai_data_{date_str}"
            
            print(f"ğŸ” æ£€æŸ¥æ—¥æœŸ: {date_str} (key: {kv_key})")
            data_str = kv_read(self.account_id, self.namespace_id, self.api_token, kv_key)
            
            if data_str:
                print(f"âœ… æ‰¾åˆ°æ•°æ®: {date_str}")
                return kv_key, data_str
            else:
                print(f"âŒ æœªæ‰¾åˆ°æ•°æ®: {date_str}")
        
        print(f"âš ï¸ å‘å‰æŸ¥æ‰¾äº† {max_days_back} å¤©ï¼Œæœªæ‰¾åˆ°ä»»ä½•æ•°æ®")
        return None, None
    
    def get_keywords_by_rank(self, processed_data):
        """æŒ‰æ’åé¡ºåºè·å–å…³é”®è¯åˆ—è¡¨"""
        keywords_list = []
        
        for page_key, page in processed_data['pages'].items():
            for item in page['wordRankList']:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡é¢˜ä¸”çŠ¶æ€ä¸ºgenerated
                if ('titles' in item and item['titles'] and 
                    item.get('article_status') == 'generated'):
                    
                    # è·å–æœªä½¿ç”¨çš„æ ‡é¢˜
                    unused_titles = [title_obj for title_obj in item['titles'] 
                                   if title_obj.get('use_count', 0) == 0]
                    
                    if unused_titles:
                        keywords_list.append({
                            'keyword': item['word'],
                            'rank': item.get('rank', 999999),
                            'titles': unused_titles,
                            'page_key': page_key
                        })
        
        # æŒ‰æ’åæ’åº
        keywords_list.sort(key=lambda x: x['rank'])
        return keywords_list
    
    def get_all_unused_titles_by_rank(self, processed_data):
        """æŒ‰å…³é”®è¯æ’åé¡ºåºè·å–æ‰€æœ‰æœªä½¿ç”¨çš„æ ‡é¢˜åˆ—è¡¨"""
        all_titles = []
        
        for page_key, page in processed_data['pages'].items():
            for item in page['wordRankList']:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡é¢˜ä¸”çŠ¶æ€ä¸ºgenerated
                if ('titles' in item and item['titles'] and 
                    item.get('article_status') == 'generated'):
                    
                    keyword_rank = item.get('rank', 999999)
                    
                    # è·å–æœªä½¿ç”¨çš„æ ‡é¢˜
                    unused_titles = [title_obj for title_obj in item['titles'] 
                                   if title_obj.get('use_count', 0) == 0]
                    
                    # ä¸ºæ¯ä¸ªæ ‡é¢˜æ·»åŠ å…³é”®è¯ä¿¡æ¯
                    for title_obj in unused_titles:
                        all_titles.append({
                            'title_obj': title_obj,
                            'keyword': item['word'],
                            'keyword_rank': keyword_rank,
                            'page_key': page_key
                        })
        
        # æŒ‰å…³é”®è¯æ’åæ’åº
        all_titles.sort(key=lambda x: x['keyword_rank'])
        return all_titles

    def _count_today_published_by_repo(self, repo_name):
        """ä»è¿œç¨‹ä»“åº“ç»Ÿè®¡æŸä¸ªä»“åº“ä»Šå¤©å·²å‘å¸ƒçš„æ–‡ç« æ•°é‡ï¼ˆæŒ‰æ–‡ç« æ–‡ä»¶å¤¹è®¡æ•°ï¼‰"""
        try:
            # è·å–å¯ç”¨çš„ä»“åº“é…ç½®
            enabled_repos = self.article_generator.repo_manager.get_enabled_repositories()
            git_repos = {k: v for k, v in enabled_repos.items() if v['type'] == 'git'}
            
            # æŸ¥æ‰¾å¯¹åº”çš„ä»“åº“é…ç½®
            target_repo_config = None
            for repo_id, repo_config in git_repos.items():
                if repo_config.get('name') == repo_name:
                    target_repo_config = repo_config
                    break
            
            if not target_repo_config:
                print(f"âš ï¸ æœªæ‰¾åˆ°ä»“åº“é…ç½®: {repo_name}")
                return 0
            
            # ä½¿ç”¨RepositoryManageræŸ¥è¯¢è¿œç¨‹ä»“åº“æ–‡ä»¶å¤¹æ•°é‡
            folder_count = self.article_generator.repo_manager.query_remote_repository_folders(target_repo_config)
            print(f"ğŸ“Š è¿œç¨‹ä»“åº“ {repo_name} ä»Šå¤©å·²å‘å¸ƒæ–‡ç« æ•°é‡: {folder_count}")
            return folder_count
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢è¿œç¨‹ä»“åº“ {repo_name} å¤±è´¥: {str(e)}")
            return 0

    def _get_today_site_published_counts(self):
        """æŒ‰ç½‘ç«™ç´¢å¼•ç»Ÿè®¡ä»Šå¤©å·²å‘å¸ƒæ•°é‡ï¼ˆé€šè¿‡å„è‡ªä»“åº“ååœ¨ logs/backup ä¸‹ç»Ÿè®¡ï¼‰"""
        counts = {}
        try:
            enabled_repos = self.article_generator.repo_manager.get_enabled_repositories()
            # ä»…è€ƒè™‘ Git ä»“åº“å¹¶æŒ‰ get_repository_for_site çš„æ’åºæ–¹å¼
            git_repos = {k: v for k, v in enabled_repos.items() if v['type'] == 'git'}
            sorted_repos = sorted(git_repos.items())
            for site_index, (repo_id, repo_config) in enumerate(sorted_repos):
                repo_name = repo_config.get('name', str(repo_id))
                counts[site_index] = self._count_today_published_by_repo(repo_name)
        except Exception:
            # å¤±è´¥åˆ™å…¨éƒ¨ç½®é›¶
            for i in range(self.total_sites):
                counts[i] = 0
        return counts
    
    def determine_target_site(self, rank_index):
        """ä½¿ç”¨é™¤ä½™æ–¹å¼ç¡®å®šç›®æ ‡ç½‘ç«™"""
        # ä½¿ç”¨æ’åç´¢å¼•çš„é™¤ä½™æ¥ç¡®å®šç›®æ ‡ç½‘ç«™
        site_index = rank_index % self.total_sites
        return site_index
    
    def get_repository_for_site(self, site_index):
        """æ ¹æ®ç½‘ç«™ç´¢å¼•è·å–å¯¹åº”çš„ä»“åº“é…ç½®"""
        enabled_repos = self.article_generator.repo_manager.get_enabled_repositories()
        git_repos = {k: v for k, v in enabled_repos.items() if v['type'] == 'git'}
        
        if not git_repos:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„Gitä»“åº“")
            return None
        
        # å°†ä»“åº“æŒ‰IDæ’åºï¼Œç¡®ä¿ä¸€è‡´æ€§
        sorted_repos = sorted(git_repos.items())
        
        if site_index < len(sorted_repos):
            repo_id, repo_config = sorted_repos[site_index]
            print(f"ğŸ“ ç½‘ç«™ {site_index} å¯¹åº”ä»“åº“: {repo_config['name']}")
            return repo_id, repo_config
        else:
            print(f"âŒ ç½‘ç«™ç´¢å¼• {site_index} è¶…å‡ºèŒƒå›´")
            return None
    
    def publish_daily_articles(self, need_images=True, articles_per_site=None, max_workers=None, batch_size=None):
        """æ‰§è¡Œæ¯æ—¥æ–‡ç« å‘å¸ƒ - æ”¯æŒå¹¶è¡Œå’Œä¸²è¡Œä¸¤ç§æ¨¡å¼"""
        if not self.enabled:
            print("âŒ æ¯æ—¥å‘å¸ƒåŠŸèƒ½å·²ç¦ç”¨")
            return False
        
        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰ä¼ å…¥åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
        if articles_per_site is not None:
            actual_articles_per_site = articles_per_site
            print(f"ğŸ“ ä½¿ç”¨å·¥ä½œæµæŒ‡å®šæ•°é‡: {articles_per_site}")
        else:
            actual_articles_per_site = self.articles_per_site
            print(f"ğŸ“ ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤æ•°é‡: {self.articles_per_site}")
        
        # å¤„ç†å¹¶è¡Œé…ç½®å‚æ•°
        if max_workers is not None:
            print(f"ğŸ”§ ä½¿ç”¨å·¥ä½œæµæŒ‡å®šçº¿ç¨‹æ•°: {max_workers}")
        if batch_size is not None:
            print(f"ğŸ”§ ä½¿ç”¨å·¥ä½œæµæŒ‡å®šæ‰¹æ¬¡å¤§å°: {batch_size}")
        
        print("=== å¼€å§‹æ¯æ—¥æ–‡ç« å‘å¸ƒ ===")
        print(f"ğŸ¯ ç›®æ ‡: æ¯ä¸ªç½‘ç«™å‘å¸ƒ {actual_articles_per_site} ç¯‡æ–‡ç« ")
        print(f"ğŸŒ æ€»ç½‘ç«™æ•°: {self.total_sites}")
        
        # æ ¹æ®é…ç½®é€‰æ‹©å¹¶è¡Œæˆ–ä¸²è¡Œæ¨¡å¼
        if self.parallel_enabled:
            print("ğŸš€ ä½¿ç”¨å¹¶è¡Œç”Ÿæˆæ¨¡å¼")
            return self.publish_daily_articles_parallel(need_images, actual_articles_per_site, max_workers, batch_size)
        else:
            print("ğŸ”„ ä½¿ç”¨ä¸²è¡Œç”Ÿæˆæ¨¡å¼")
            return self.publish_daily_articles_serial(need_images, actual_articles_per_site)
    
    def publish_daily_articles_parallel(self, need_images=True, articles_per_site=100, max_workers=None, batch_size=None):
        """æ‰§è¡Œæ¯æ—¥æ–‡ç« å‘å¸ƒ - å¹¶è¡Œç‰ˆæœ¬"""
        # åŠ¨æ€æ›´æ–°å¹¶è¡Œç”Ÿæˆå™¨çš„é…ç½®
        if max_workers is not None:
            self.parallel_generator.max_workers = max_workers
            print(f"ğŸ”§ åŠ¨æ€è®¾ç½®çº¿ç¨‹æ•°: {max_workers}")
        
        if batch_size is not None:
            self.parallel_generator.batch_size = batch_size
            self.batch_size = batch_size  # åŒæ—¶æ›´æ–°PublishManagerçš„batch_size
            print(f"ğŸ”§ åŠ¨æ€è®¾ç½®æ‰¹æ¬¡å¤§å°: {batch_size}")
        
        print(f"âš™ï¸ å½“å‰å¹¶è¡Œé…ç½®: {self.parallel_generator.max_workers} ä¸ªçº¿ç¨‹, æ‰¹æ¬¡å¤§å° {self.parallel_generator.batch_size}")
        
        # æŸ¥æ‰¾æœ€æ–°æ•°æ®
        kv_key, existing_data_str = self.find_latest_kv_data()
        if not existing_data_str:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•KVæ•°æ®")
            return False
        
        processed_data = json.loads(existing_data_str)
        
        # æŒ‰æ’åè·å–æ‰€æœ‰æœªä½¿ç”¨çš„æ ‡é¢˜ï¼Œå¹¶éšæœºæ‰“ä¹±é¡ºåºè¿›è¡Œå‘å¸ƒ
        all_titles = self.get_all_unused_titles_by_rank(processed_data)
        import random
        random.shuffle(all_titles)
        print(f"ğŸ“Š æ‰¾åˆ° {len(all_titles)} ä¸ªå¯å‘å¸ƒçš„æ ‡é¢˜ï¼ˆå·²éšæœºæ‰“ä¹±ï¼‰")
        if not all_titles:
            print("âŒ å‰500åå…³é”®è¯ä¸­æ²¡æœ‰å¯å‘å¸ƒçš„æœªä½¿ç”¨æ ‡é¢˜")
            return False
        
        if len(all_titles) < articles_per_site * self.total_sites:
            print(f"âš ï¸ å¯å‘å¸ƒæ ‡é¢˜æ•°é‡ ({len(all_titles)}) å°‘äºæ‰€éœ€æ•°é‡ ({articles_per_site * self.total_sites})")
            print("ğŸ”„ å°†ç»§ç»­å‘å¸ƒå¯ç”¨çš„æ ‡é¢˜")
        
        # ç»Ÿè®¡ä¿¡æ¯ï¼ˆä»æ—¥å¿—ç›®å½•è¯»å–ä»Šå¤©å·²å‘å¸ƒæ•°é‡ï¼‰
        site_stats = {}
        today_counts = self._get_today_site_published_counts()
        for i in range(self.total_sites):
            already = today_counts.get(i, 0)
            site_stats[i] = {
                'published': already,
                'failed': 0,
                'target': articles_per_site
            }
        print("ğŸ—‚ï¸ ä»Šæ—¥å„ç½‘ç«™å·²å‘å¸ƒæ•°(æ¥è‡ªlogs): " + ", ".join([f"site {i}: {site_stats[i]['published']}" for i in range(self.total_sites)]))
        
        # è®¡ç®—éœ€è¦å‘å¸ƒçš„æ€»æ•°é‡
        total_needed = sum(max(0, site_stats[i]['target'] - site_stats[i]['published']) for i in range(self.total_sites))
        if total_needed == 0:
            print("âœ… æ‰€æœ‰ç½‘ç«™å‡å·²è¾¾åˆ°ç›®æ ‡å‘å¸ƒæ•°é‡")
            return True
        
        # é€‰æ‹©éœ€è¦å‘å¸ƒçš„æ ‡é¢˜
        titles_to_publish = all_titles[:total_needed]
        print(f"ğŸ“ å°†å‘å¸ƒ {len(titles_to_publish)} ç¯‡æ–‡ç« ")
        
        # åˆ†æ‰¹å¹¶è¡Œç”Ÿæˆæ–‡ç« 
        return self._process_articles_in_batches(titles_to_publish, need_images, kv_key, processed_data, site_stats)
    
    def _process_articles_in_batches(self, titles_to_publish, need_images, kv_key, processed_data, site_stats):
        """åˆ†æ‰¹å¹¶è¡Œå¤„ç†æ–‡ç« ç”Ÿæˆå’Œä¸Šä¼ """
        total_published = 0
        total_failed = 0
        used_titles_today = set()
        circuit_breaker_triggered = False
        
        # æŒ‰ç½‘ç«™å¾ªç¯å¤„ç†ï¼Œè€Œä¸æ˜¯æŒ‰æ–‡ç« æ€»æ•°åˆ†æ‰¹
        while True:
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç½‘ç«™éœ€è¦æ–‡ç« 
            available_sites = [i for i in range(self.total_sites) if site_stats[i]['published'] < site_stats[i]['target']]
            if not available_sites:
                print("âœ… æ‰€æœ‰ç½‘ç«™å‡å·²è¾¾åˆ°å½“æ—¥ç›®æ ‡")
                break
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªéœ€è¦æ–‡ç« çš„ç½‘ç«™
            import random
            target_site = random.choice(available_sites)
            
            # è·å–ç›®æ ‡ä»“åº“ä¿¡æ¯
            repo_info = self.get_repository_for_site(target_site)
            if not repo_info:
                print(f"âŒ æ— æ³•è·å–ç½‘ç«™ {target_site} çš„ä»“åº“é…ç½®")
                site_stats[target_site]['failed'] += 1
                continue
            
            repo_id, repo_config = repo_info
            
            # è®¡ç®—è¯¥ç½‘ç«™è¿˜éœ€è¦å¤šå°‘ç¯‡æ–‡ç« 
            remaining_articles = site_stats[target_site]['target'] - site_stats[target_site]['published']
            if remaining_articles <= 0:
                print(f"âœ… ç½‘ç«™ {target_site} å·²è¾¾åˆ°ç›®æ ‡æ•°é‡")
                continue
            
            # ç¡®å®šæœ¬æ‰¹æ¬¡è¦å¤„ç†çš„æ–‡ç« æ•°é‡ï¼ˆä¸è¶…è¿‡æ‰¹å¤„ç†å¤§å°å’Œå‰©ä½™éœ€æ±‚ï¼‰
            batch_size_for_site = min(self.batch_size, remaining_articles)
            
            # ä»å¯ç”¨æ ‡é¢˜ä¸­é€‰æ‹©æœ¬æ‰¹æ¬¡è¦å¤„ç†çš„æ ‡é¢˜
            batch_titles = []
            for title_info in titles_to_publish:
                if len(batch_titles) >= batch_size_for_site:
                    break
                    
                title_text = title_info['title_obj'].get('title', '')
                if title_text not in used_titles_today:
                    batch_titles.append(title_info)
                    used_titles_today.add(title_text)
            
            if not batch_titles:
                print("â­ï¸ æ²¡æœ‰å¯ç”¨çš„æ ‡é¢˜")
                break
            
            print(f"\nğŸ“¦ å¤„ç†ç½‘ç«™ {target_site} ({repo_config['name']}): {len(batch_titles)} ä¸ªä»»åŠ¡")
            print(f"   ç›®æ ‡: {site_stats[target_site]['target']} ç¯‡, å·²å‘å¸ƒ: {site_stats[target_site]['published']} ç¯‡, å‰©ä½™: {remaining_articles} ç¯‡")
            
            # åˆ›å»ºå¹¶è¡Œç”Ÿæˆä»»åŠ¡
            article_tasks = self.parallel_generator.create_article_tasks(
                batch_titles, 
                need_images, 
                repo_config.get('name'),
                repo_config
            )
            
            print(f"ğŸš€ å¼€å§‹å¹¶è¡Œç”Ÿæˆ {len(article_tasks)} ä¸ªæ–‡ç« åˆ°ç½‘ç«™ {target_site}...")
            
            try:
                # å¹¶è¡Œç”Ÿæˆæ–‡ç« 
                generation_results = self.parallel_generator.generate_articles_parallel(article_tasks)
                
                # æ”¶é›†æˆåŠŸç”Ÿæˆçš„æ–‡ç« 
                successful_articles = []
                failed_count = 0
                
                for result in generation_results:
                    if result['success']:
                        successful_articles.append(result)
                        print(f"   âœ… æ–‡ç«  #{result['task_id']} ç”ŸæˆæˆåŠŸ: {result['keyword']}")
                    else:
                        failed_count += 1
                        print(f"   âŒ æ–‡ç«  #{result['task_id']} ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯APIé‡è¯•è€—å°½é”™è¯¯
                        if result.get('error_type') == 'api_exhausted':
                            print("â›” æ£€æµ‹åˆ°APIé‡è¯•è€—å°½é”™è¯¯ï¼Œè§¦å‘ç†”æ–­æœºåˆ¶")
                            circuit_breaker_triggered = True
                            break
                
                # å¦‚æœæœ‰æˆåŠŸç”Ÿæˆçš„æ–‡ç« ï¼Œä¸Šä¼ åˆ°ç›®æ ‡ç½‘ç«™
                if successful_articles and not circuit_breaker_triggered:
                    print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼  {len(successful_articles)} ç¯‡æ–‡ç« åˆ°ç½‘ç«™ {target_site}...")
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºè¯¥ç½‘ç«™çš„æœ€åä¸€æ¬¡ä¸Šä¼ 
                    articles_to_publish_count = len(successful_articles)
                    is_final_commit_for_site = (site_stats[target_site]['published'] + articles_to_publish_count >= site_stats[target_site]['target'])
                    
                    if is_final_commit_for_site:
                        print(f"ğŸš€ è¿™æ˜¯ç½‘ç«™ {target_site} çš„æœ€åä¸€æ¬¡æäº¤ï¼Œå°†è§¦å‘è‡ªåŠ¨éƒ¨ç½²")
                    else:
                        print(f"ğŸ“ æ™®é€šæäº¤åˆ°ç½‘ç«™ {target_site}ï¼Œè·³è¿‡è‡ªåŠ¨éƒ¨ç½²")
                    
                    # æ‰¹é‡ä¸Šä¼ æ‰€æœ‰æˆåŠŸçš„æ–‡ç« 
                    batch_upload_success = self._batch_upload_articles(
                        successful_articles, target_site, repo_id, repo_config, 
                        is_final_commit_for_site, kv_key, processed_data, batch_titles
                    )
                    
                    if batch_upload_success:
                        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                        site_stats[target_site]['published'] += len(successful_articles)
                        total_published += len(successful_articles)
                        print(f"âœ… ä¸Šä¼ æˆåŠŸ: {len(successful_articles)} ç¯‡æ–‡ç« å·²å‘å¸ƒåˆ°ç½‘ç«™ {target_site}")
                        print(f"   ç½‘ç«™ {target_site} è¿›åº¦: {site_stats[target_site]['published']}/{site_stats[target_site]['target']}")
                    else:
                        site_stats[target_site]['failed'] += len(successful_articles)
                        total_failed += len(successful_articles)
                        print(f"âŒ ä¸Šä¼ å¤±è´¥")
                
                # æ›´æ–°å¤±è´¥ç»Ÿè®¡
                site_stats[target_site]['failed'] += failed_count
                total_failed += failed_count
                
                # æ£€æŸ¥æ˜¯å¦è§¦å‘ç†”æ–­æœºåˆ¶
                if circuit_breaker_triggered:
                    print("â›” ç†”æ–­æœºåˆ¶å·²è§¦å‘ï¼Œåœæ­¢å¤„ç†")
                    break
                
            except ApiExhaustedRetriesError as e:
                print(f"ğŸ’¥ ç½‘ç«™ {target_site} å¤„ç†ä¸­å‘ç”ŸAPIé‡è¯•è€—å°½å¼‚å¸¸: {str(e)}")
                circuit_breaker_triggered = True
                break
            except Exception as e:
                print(f"âŒ ç½‘ç«™ {target_site} å¤„ç†å¼‚å¸¸: {str(e)}")
                site_stats[target_site]['failed'] += len(batch_titles)
                total_failed += len(batch_titles)
                continue
        
        # æ£€æŸ¥æ˜¯å¦è§¦å‘äº†ç†”æ–­æœºåˆ¶
        if circuit_breaker_triggered:
            print("\nğŸ”¥ ç†”æ–­æœºåˆ¶å·²è§¦å‘ï¼Œåœæ­¢æ–‡ç« å‘å¸ƒæµç¨‹")
            # æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘å·¥ä½œæµå»¶è¿Ÿæœºåˆ¶
            raise ApiExhaustedRetriesError("ğŸ”¥ APIæœåŠ¡è¿ç»­å¤±è´¥ï¼Œè§¦å‘ç†”æ–­æœºåˆ¶ï¼Œè¯·ç¨åé‡è¯•")
        
        # è¾“å‡ºå‘å¸ƒç»Ÿè®¡
        print("\n=== æŒ‰ç½‘ç«™åˆ†æ‰¹å‘å¸ƒå®Œæˆ ===")
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  - æ€»å‘å¸ƒæˆåŠŸ: {total_published}")
        print(f"  - æ€»å‘å¸ƒå¤±è´¥: {total_failed}")
        
        print(f"\nğŸ“ˆ å„ç½‘ç«™ç»Ÿè®¡:")
        for site_index in range(self.total_sites):
            stats = site_stats[site_index]
            repo_info = self.get_repository_for_site(site_index)
            repo_name = repo_info[1]['name'] if repo_info else f"ç½‘ç«™{site_index}"
            
            print(f"  - {repo_name}: {stats['published']}/{stats['target']} æˆåŠŸ, {stats['failed']} å¤±è´¥")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç½‘ç«™éƒ½è¾¾åˆ°äº†ç›®æ ‡æ•°é‡
        all_sites_reached_target = all(site_stats[i]['published'] >= site_stats[i]['target'] for i in range(self.total_sites))
        
        if all_sites_reached_target:
            print("âœ… æ‰€æœ‰ç½‘ç«™å‡å·²è¾¾åˆ°ç›®æ ‡å‘å¸ƒæ•°é‡ï¼Œä»»åŠ¡å®Œæˆ")
            return True
        elif total_published > 0:
            print("âœ… éƒ¨åˆ†æ–‡ç« å‘å¸ƒæˆåŠŸ")
            return True
        else:
            print("âŒ æ²¡æœ‰æ–‡ç« å‘å¸ƒæˆåŠŸ")
            return False
    
    def _batch_upload_articles(self, successful_articles, target_site, repo_id, repo_config, 
                              is_final_commit, kv_key, processed_data, valid_titles):
        """æ‰¹é‡ä¸Šä¼ æ–‡ç« åˆ°æŒ‡å®šç½‘ç«™ - æ‰€æœ‰æ–‡ç« ä¸€æ¬¡æ€§æäº¤"""
        try:
            print(f"   ğŸ“¤ å‡†å¤‡æ‰¹é‡ä¸Šä¼  {len(successful_articles)} ç¯‡æ–‡ç« åˆ° {repo_config['name']}")
            
            # æ”¶é›†æ‰€æœ‰æ–‡ç« çš„æ–‡ä»¶è·¯å¾„ï¼Œå‡†å¤‡æ‰¹é‡ä¸Šä¼ 
            all_article_paths = []
            article_infos = []
            
            for result in successful_articles:
                # æ”¶é›†æ¯ç¯‡æ–‡ç« çš„æ‰€æœ‰è¯­è¨€ç‰ˆæœ¬æ–‡ä»¶
                for lang_code, lang_result in result['results'].items():
                    if not lang_result['error'] and lang_result['file']:
                        article_path = lang_result['file']
                        all_article_paths.append(article_path)
                        
                        # å‡†å¤‡æ–‡ç« ä¿¡æ¯
                        article_info = {
                            'title': f'Batch Upload Article #{result["task_id"]}',
                            'keyword': result['keyword'],
                            'game_name': '',
                            'custom_suffix': '',
                            'language': lang_code,
                            'folder_name': Path(article_path).name,
                            'need_images': True,
                            'file_path': article_path,
                            'image_dir': str(Path(article_path) / 'images'),
                            'task_id': result['task_id']
                        }
                        article_infos.append(article_info)
            
            if not all_article_paths:
                print(f"   âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ–‡ç« æ–‡ä»¶å¯ä»¥ä¸Šä¼ ")
                return False
            
            print(f"   ğŸ“ æ”¶é›†åˆ° {len(all_article_paths)} ä¸ªæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰è¯­è¨€ç‰ˆæœ¬ï¼‰")
            
            # æ‰¹é‡ä¸Šä¼ æ‰€æœ‰æ–‡ç« æ–‡ä»¶åˆ°æŒ‡å®šä»“åº“
            batch_upload_result = self._upload_batch_to_repository(
                all_article_paths, article_infos, repo_id, repo_config, is_final_commit
            )
            
            if batch_upload_result['success']:
                print(f"   âœ… æ‰¹é‡ä¸Šä¼ æˆåŠŸ: {len(successful_articles)} ç¯‡æ–‡ç« å·²å‘å¸ƒåˆ° {repo_config['name']}")
                
                if is_final_commit:
                    print(f"   ğŸš€ å·²è§¦å‘è‡ªåŠ¨éƒ¨ç½²")
                
                # æ›´æ–°æ‰€æœ‰æ–‡ç« çš„æ ‡é¢˜ä½¿ç”¨è®°å½•
                for result in successful_articles:
                    # æ‰¾åˆ°å¯¹åº”çš„æ ‡é¢˜ä¿¡æ¯
                    title_info = None
                    for valid_title in valid_titles:
                        if valid_title['title_obj'].get('title', '') in result['keyword']:
                            title_info = valid_title
                            break
                    
                    if title_info:
                        title_obj = title_info['title_obj']
                        title_obj['use_count'] = title_obj.get('use_count', 0) + 1
                        title_obj['last_used_at'] = datetime.now(beijing_tz).isoformat()
                        title_obj['published_to_site'] = target_site
                        title_obj['published_to_repo'] = repo_id
                        title_obj['was_final_commit'] = is_final_commit
                        title_obj['task_id'] = result['task_id']
                        title_obj['batch_upload'] = True  # æ ‡è®°ä¸ºæ‰¹é‡ä¸Šä¼ 
                        title_obj['batch_size'] = len(successful_articles)  # è®°å½•æ‰¹æ¬¡å¤§å°
                
                # ä¿å­˜åˆ°KVå­˜å‚¨ï¼ˆæ‰¹é‡ä¿å­˜ä¸€æ¬¡ï¼‰
                self.save_to_kv(kv_key, processed_data)
                print(f"   ğŸ’¾ å·²æ›´æ–°KVå­˜å‚¨è®°å½•")
                
                return True
            else:
                print(f"   âŒ æ‰¹é‡ä¸Šä¼ å¤±è´¥: {batch_upload_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return False
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡ä¸Šä¼ å¼‚å¸¸: {str(e)}")
            return False
    
    def _upload_batch_to_repository(self, all_article_paths, article_infos, repo_id, repo_config, is_final_commit):
        """æ‰¹é‡ä¸Šä¼ å¤šä¸ªæ–‡ç« åˆ°æŒ‡å®šä»“åº“ - çœŸæ­£çš„ä¸€æ¬¡æ€§ä¸Šä¼ """
        try:
            print(f"   ğŸš€ å¼€å§‹çœŸæ­£çš„æ‰¹é‡ä¸Šä¼  {len(all_article_paths)} ä¸ªæ–‡ä»¶åˆ° {repo_config['name']}...")
            
            # å‡†å¤‡æ‰¹é‡ä¸Šä¼ æ•°æ®
            batch_articles = []
            
            for i, article_path in enumerate(all_article_paths):
                article_info = article_infos[i] if i < len(article_infos) else {}
                
                # ä¸ºæ¯ä¸ªæ–‡ç« æ–‡ä»¶åˆ›å»ºæ‰¹é‡ä¸Šä¼ é¡¹
                batch_item = {
                    'path': article_path,
                    'info': {
                        'title': article_info.get('title', f'Article #{article_info.get("task_id", i+1)}'),
                        'keyword': article_info.get('keyword', f'keyword_{i+1}'),
                        'game_name': article_info.get('game_name', ''),
                        'custom_suffix': article_info.get('custom_suffix', ''),
                        'language': article_info.get('language', 'unknown'),
                        'folder_name': Path(article_path).name,
                        'need_images': True,
                        'file_path': article_path,
                        'image_dir': str(Path(article_path) / 'images'),
                        'task_id': article_info.get('task_id', i+1)
                    }
                }
                
                batch_articles.append(batch_item)
                print(f"     ğŸ“„ å‡†å¤‡ä¸Šä¼ : {Path(article_path).name} (ä»»åŠ¡#{batch_item['info']['task_id']})")
            
            print(f"   ğŸ“¦ å‡†å¤‡ä¸€æ¬¡æ€§æäº¤ {len(batch_articles)} ä¸ªæ–‡ä»¶...")
            
            # ä½¿ç”¨ä»“åº“ç®¡ç†å™¨çš„æ‰¹é‡ä¸Šä¼ åŠŸèƒ½
            upload_result = self.article_generator.repo_manager.upload_to_git_repository(
                source_path=None,  # æ‰¹é‡æ¨¡å¼ä¸‹ä¸éœ€è¦å•ä¸ªsource_path
                repo_config=repo_config,
                article_info={},   # æ‰¹é‡æ¨¡å¼ä¸‹ä¸éœ€è¦å•ä¸ªarticle_info
                repo_id=repo_id,
                is_final_commit=is_final_commit,
                batch_articles=batch_articles
            )
            
            if upload_result.get('success', False):
                article_count = len(set(info.get('task_id') for info in article_infos))
                print(f"   âœ… æ‰¹é‡ä¸Šä¼ æˆåŠŸ: {article_count} ç¯‡æ–‡ç« å·²ä¸€æ¬¡æ€§æäº¤åˆ° {repo_config['name']}")
                if is_final_commit:
                    print(f"   ğŸš€ å·²è§¦å‘è‡ªåŠ¨éƒ¨ç½²")
                else:
                    print(f"   ğŸ“ è·³è¿‡è‡ªåŠ¨éƒ¨ç½²")
            else:
                print(f"   âŒ æ‰¹é‡ä¸Šä¼ å¤±è´¥: {upload_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            return upload_result
                
        except Exception as e:
            return {
                'success': False,
                'error': f'æ‰¹é‡ä¸Šä¼ å¼‚å¸¸: {str(e)}'
            }
    
    def publish_daily_articles_serial(self, need_images=True, articles_per_site=100):
        """æ‰§è¡Œæ¯æ—¥æ–‡ç« å‘å¸ƒ - ä¸²è¡Œç‰ˆæœ¬ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        # æŸ¥æ‰¾æœ€æ–°æ•°æ®
        kv_key, existing_data_str = self.find_latest_kv_data()
        if not existing_data_str:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•KVæ•°æ®")
            return False
        
        processed_data = json.loads(existing_data_str)
        
        # æŒ‰æ’åè·å–æ‰€æœ‰æœªä½¿ç”¨çš„æ ‡é¢˜ï¼Œå¹¶éšæœºæ‰“ä¹±é¡ºåºè¿›è¡Œå‘å¸ƒ
        all_titles = self.get_all_unused_titles_by_rank(processed_data)
        import random
        random.shuffle(all_titles)
        print(f"ğŸ“Š æ‰¾åˆ° {len(all_titles)} ä¸ªå¯å‘å¸ƒçš„æ ‡é¢˜ï¼ˆå·²éšæœºæ‰“ä¹±ï¼‰")
        if not all_titles:
            print("âŒ å‰500åå…³é”®è¯ä¸­æ²¡æœ‰å¯å‘å¸ƒçš„æœªä½¿ç”¨æ ‡é¢˜")
            return False
        
        if len(all_titles) < articles_per_site * self.total_sites:
            print(f"âš ï¸ å¯å‘å¸ƒæ ‡é¢˜æ•°é‡ ({len(all_titles)}) å°‘äºæ‰€éœ€æ•°é‡ ({articles_per_site * self.total_sites})")
            print("ğŸ”„ å°†ç»§ç»­å‘å¸ƒå¯ç”¨çš„æ ‡é¢˜")
        
        # ç»Ÿè®¡ä¿¡æ¯ï¼ˆä»æ—¥å¿—ç›®å½•è¯»å–ä»Šå¤©å·²å‘å¸ƒæ•°é‡ï¼‰
        site_stats = {}
        today_counts = self._get_today_site_published_counts()
        for i in range(self.total_sites):
            already = today_counts.get(i, 0)
            site_stats[i] = {
                'published': already,
                'failed': 0,
                'target': articles_per_site
            }
        print("ğŸ—‚ï¸ ä»Šæ—¥å„ç½‘ç«™å·²å‘å¸ƒæ•°(æ¥è‡ªlogs): " + ", ".join([f"site {i}: {site_stats[i]['published']}" for i in range(self.total_sites)]))
        
        total_published = 0
        total_failed = 0
        
        # ç¡®ä¿åŒä¸€æ ‡é¢˜ä¸ä¼šåœ¨å¤šä¸ªç½‘ç«™é‡å¤å‘å¸ƒï¼ˆæœ¬æ¬¡è¿è¡Œå†…ï¼‰
        used_titles_today = set()
        
        # ç†”æ–­æ ‡å¿—
        circuit_breaker_triggered = False

        # é€ä¸ªæ ‡é¢˜å°è¯•å‘å¸ƒï¼ˆéšæœºåˆ†é…åˆ°æœ‰å‰©ä½™é¢åº¦çš„ç½‘ç«™ï¼‰
        for title_index, title_info in enumerate(all_titles):
            # æ£€æŸ¥ç†”æ–­çŠ¶æ€
            if circuit_breaker_triggered:
                print("â›” ç†”æ–­æœºåˆ¶å·²è§¦å‘ï¼Œåœæ­¢å¤„ç†å‰©ä½™æ ‡é¢˜")
                break
            # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°ç›®æ ‡æ•°é‡
            if all(site_stats[i]['published'] >= site_stats[i]['target'] for i in range(self.total_sites)):
                print(f"âœ… æ‰€æœ‰ç½‘ç«™å·²è¾¾åˆ°ç›®æ ‡å‘å¸ƒæ•°é‡")
                break
            
            title_text = title_info['title_obj'].get('title', '')
            # ä¿è¯æ ‡é¢˜åœ¨æœ¬æ¬¡è¿è¡Œä¸­ä¸é‡å¤åˆ°ä¸¤ä¸ªå¹³å°
            if title_text in used_titles_today:
                continue
            
            # ä»å°šæœªè¾¾æ ‡çš„ç½‘ç«™ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª
            available_sites = [i for i in range(self.total_sites) if site_stats[i]['published'] < site_stats[i]['target']]
            if not available_sites:
                print("âœ… æ‰€æœ‰ç½‘ç«™å‡å·²è¾¾åˆ°å½“æ—¥ç›®æ ‡")
                break
            import random
            target_site = random.choice(available_sites)
            
            # æ£€æŸ¥ç›®æ ‡ç½‘ç«™æ˜¯å¦å·²è¾¾åˆ°å‘å¸ƒæ•°é‡
            if site_stats[target_site]['published'] >= site_stats[target_site]['target']:
                print(f"â­ï¸ ç½‘ç«™ {target_site} å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œè·³è¿‡æ ‡é¢˜åºå· {title_index}")
                continue
            
            # è·å–ç›®æ ‡ä»“åº“
            repo_info = self.get_repository_for_site(target_site)
            if not repo_info:
                print(f"âŒ æ— æ³•è·å–ç½‘ç«™ {target_site} çš„ä»“åº“é…ç½®")
                continue
            
            repo_id, repo_config = repo_info
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºè¯¥ç½‘ç«™çš„æœ€åä¸€æ¬¡ä¸Šä¼ 
            is_final_commit_for_site = (site_stats[target_site]['published'] + 1 == site_stats[target_site]['target'])
            
            print(f"\nğŸ“ å‘å¸ƒæ–‡ç« åˆ°ç½‘ç«™ {target_site} ({repo_config['name']})")
            print(f"   æ ‡é¢˜åºå·: {title_index}, å…³é”®è¯: {title_info['keyword']} (æ’å: {title_info['keyword_rank']})")
            print(f"   æ ‡é¢˜: {title_info['title_obj']['title']}")
            print(f"   è¿›åº¦: {site_stats[target_site]['published']}/{site_stats[target_site]['target']}")
            print(f"   éƒ¨ç½²çŠ¶æ€: {'ğŸš€ æœ€åä¸€æ¬¡æäº¤ï¼Œå°†è§¦å‘è‡ªåŠ¨éƒ¨ç½²' if is_final_commit_for_site else 'ğŸ“ æ™®é€šæäº¤ï¼Œè·³è¿‡è‡ªåŠ¨éƒ¨ç½²'}")
            
            # ä½¿ç”¨å½“å‰æ ‡é¢˜
            title_obj = title_info['title_obj']
            
            try:
                
                # ç”Ÿæˆæ–‡ç« ï¼ˆåªå‘å¸ƒåˆ°æŒ‡å®šä»“åº“ï¼‰
                result = self.publish_article_to_specific_site(
                    title_obj, repo_id, repo_config, need_images, title_index, is_final_commit_for_site
                )
                
                if result['success']:
                    site_stats[target_site]['published'] += 1
                    total_published += 1
                    used_titles_today.add(title_text)
                    print(f"   âœ… å‘å¸ƒæˆåŠŸ")
                    
                    # æ›´æ–°æ ‡é¢˜ä½¿ç”¨è®°å½•
                    title_obj['use_count'] = title_obj.get('use_count', 0) + 1
                    title_obj['last_used_at'] = datetime.now(beijing_tz).isoformat()
                    title_obj['published_to_site'] = target_site
                    title_obj['published_to_repo'] = repo_id
                    title_obj['was_final_commit'] = is_final_commit_for_site
                    title_obj['title_index'] = title_index
                    
                    # ä¿å­˜åˆ°KVå­˜å‚¨
                    self.save_to_kv(kv_key, processed_data)
                    
                else:
                    site_stats[target_site]['failed'] += 1
                    total_failed += 1
                    print(f"   âŒ å‘å¸ƒå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
            except ApiExhaustedRetriesError as e:
                site_stats[target_site]['failed'] += 1
                total_failed += 1
                print(f"   ğŸ’¥ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæå‰ç»ˆæ­¢: {str(e)}")
                # è®¾ç½®ç†”æ–­æ ‡å¿—
                circuit_breaker_triggered = True
                print("â›” å‘å¸ƒæµç¨‹æå‰ç»“æŸï¼Œè§¦å‘ç†”æ–­æœºåˆ¶")
                print("ğŸ”¥ ç†”æ–­æœºåˆ¶å·²è§¦å‘ï¼Œåœæ­¢æ–‡ç« å‘å¸ƒæµç¨‹")
                # ç«‹å³è·³å‡ºå¾ªç¯ï¼Œä¸å†å¤„ç†å‰©ä½™æ ‡é¢˜
                break
            except Exception as e:
                site_stats[target_site]['failed'] += 1
                total_failed += 1
                print(f"   ğŸ’¥ å‘å¸ƒå¼‚å¸¸: {str(e)}")
        
        # æ£€æŸ¥æ˜¯å¦è§¦å‘äº†ç†”æ–­æœºåˆ¶
        if circuit_breaker_triggered:
            print("\nğŸ”¥ ç†”æ–­æœºåˆ¶å·²è§¦å‘ï¼Œåœæ­¢æ–‡ç« å‘å¸ƒæµç¨‹")
            # æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘å·¥ä½œæµå»¶è¿Ÿæœºåˆ¶
            raise ApiExhaustedRetriesError("ğŸ”¥ APIæœåŠ¡è¿ç»­å¤±è´¥ï¼Œè§¦å‘ç†”æ–­æœºåˆ¶ï¼Œè¯·ç¨åé‡è¯•")
        
        # è¾“å‡ºå‘å¸ƒç»Ÿè®¡
        print("\n=== æ¯æ—¥å‘å¸ƒå®Œæˆ ===")
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  - æ€»å‘å¸ƒæˆåŠŸ: {total_published}")
        print(f"  - æ€»å‘å¸ƒå¤±è´¥: {total_failed}")
        
        print(f"\nğŸ“ˆ å„ç½‘ç«™ç»Ÿè®¡:")
        for site_index in range(self.total_sites):
            stats = site_stats[site_index]
            repo_info = self.get_repository_for_site(site_index)
            repo_name = repo_info[1]['name'] if repo_info else f"ç½‘ç«™{site_index}"
            
            print(f"  - {repo_name}: {stats['published']}/{stats['target']} æˆåŠŸ, {stats['failed']} å¤±è´¥")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç½‘ç«™éƒ½è¾¾åˆ°äº†ç›®æ ‡æ•°é‡
        all_sites_reached_target = all(site_stats[i]['published'] >= site_stats[i]['target'] for i in range(self.total_sites))
        
        if all_sites_reached_target:
            print("âœ… æ‰€æœ‰ç½‘ç«™å‡å·²è¾¾åˆ°ç›®æ ‡å‘å¸ƒæ•°é‡ï¼Œä»»åŠ¡å®Œæˆ")
            return True
        elif total_published > 0:
            print("âœ… éƒ¨åˆ†æ–‡ç« å‘å¸ƒæˆåŠŸ")
            return True
        else:
            print("âŒ æ²¡æœ‰æ–‡ç« å‘å¸ƒæˆåŠŸ")
            return False
    
    def publish_article_to_specific_site(self, title_obj, repo_id, repo_config, need_images, rank_index, is_final_commit=False):
        """å‘å¸ƒæ–‡ç« åˆ°æŒ‡å®šç½‘ç«™"""
        try:
            # æ„å»ºå…³é”®è¯å­—ç¬¦ä¸²
            article_title = title_obj.get('title', '')
            custom_suffix = title_obj.get('custom_suffix', '')
            game_name = title_obj.get('game_name', '')
            
            # ä½¿ç”¨ sanitize_filename å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼Œç¡®ä¿æ ‡é¢˜å®‰å…¨
            article_title = self.article_generator.sanitize_filename(article_title)
            custom_suffix = self.article_generator.sanitize_filename(custom_suffix)
            game_name = self.article_generator.sanitize_filename(game_name)
            
            if custom_suffix and game_name:
                keyword = f"{article_title}----{custom_suffix}----{game_name}"
            elif game_name:
                keyword = f"{article_title}----{game_name}"
            else:
                keyword = article_title
            
            print(f"   æ­£åœ¨ç”Ÿæˆæ–‡ç« : {keyword}")
            
            # ç”Ÿæˆæ–‡ç« å†…å®¹ï¼ˆåªç”Ÿæˆï¼Œä¸ä¸Šä¼ åˆ°æ‰€æœ‰ä»“åº“ï¼‰ï¼Œä¼ é€’ä»“åº“åå’Œé…ç½®
            results = self.generate_article_content_only(keyword, need_images, repo_config.get('name', repo_id), repo_config)
            
            # æ£€æŸ¥ç”Ÿæˆç»“æœ
            success_count = 0
            error_count = 0
            
            for lang_code, result in results.items():
                if result['error']:
                    error_count += 1
                    print(f"     âŒ {lang_code} ç‰ˆæœ¬ç”Ÿæˆå¤±è´¥: {result['error']}")
                else:
                    success_count += 1
                    print(f"     âœ… {lang_code} ç‰ˆæœ¬ç”ŸæˆæˆåŠŸ")
            
            if success_count > 0:
                # ä¸Šä¼ åˆ°æŒ‡å®šä»“åº“
                upload_results = self.upload_to_specific_repository(results, repo_id, repo_config, is_final_commit)
                
                return {
                    'success': True,
                    'upload_results': upload_results,
                    'usage_records': []
                }
            else:
                return {
                    'success': False,
                    'error': 'æ‰€æœ‰è¯­è¨€ç‰ˆæœ¬ç”Ÿæˆå¤±è´¥'
                }
                
        except ApiExhaustedRetriesError as e:
            # é‡æ–°æŠ›å‡ºç†”æ–­å¼‚å¸¸ï¼Œè®©ä¸Šå±‚å¤„ç†
            raise e
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def generate_article_content_only(self, keyword, need_images=True, repo_name=None, repo_config=None):
        """åªç”Ÿæˆæ–‡ç« å†…å®¹ï¼Œä¸ä¸Šä¼ åˆ°ä»»ä½•ä»“åº“ - ä½¿ç”¨ç¿»è¯‘æ¨¡å¼"""
        results = {}
        primary_content = None
        
        # è·å–æ‰€æœ‰è¯­è¨€ä»£ç 
        from article_generator import LANGUAGES
        language_codes = list(LANGUAGES.keys())
        
        # ä»ä»“åº“é…ç½®ä¸­è·å–ä¸»è¯­è¨€ï¼Œå¦‚æœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼
        if repo_config and 'primary_language' in repo_config:
            primary_lang = repo_config['primary_language']
            print(f"    ä½¿ç”¨ä»“åº“é…ç½®çš„ä¸»è¯­è¨€: {primary_lang}")
        else:
            primary_lang = 'zh-cn'  # é»˜è®¤ä¸»è¯­è¨€
            print(f"    ä½¿ç”¨é»˜è®¤ä¸»è¯­è¨€: {primary_lang}")
        
        # é¦–å…ˆç”Ÿæˆä¸»è¯­è¨€ç‰ˆæœ¬ï¼Œè·å–å†…å®¹å’Œå›¾ç‰‡æ•°æ®
        print(f"    æ­£åœ¨ç”Ÿæˆä¸»è¯­è¨€ {LANGUAGES[primary_lang]} ç‰ˆæœ¬...")
        file_path, error, usage_record, primary_content, shared_image_data = self.article_generator.generate_markdown_for_language_with_content_and_images(
            keyword, need_images, primary_lang, False, repo_name
        )
        
        results[primary_lang] = {
            'file': file_path,
            'error': error,
            'language': LANGUAGES[primary_lang],
            'usage_record': usage_record
        }
        
        if not primary_content or error:
            print(f"    âŒ ä¸»è¯­è¨€ç‰ˆæœ¬ç”Ÿæˆå¤±è´¥ï¼Œæ— æ³•ç»§ç»­ç”Ÿæˆå…¶ä»–è¯­è¨€ç‰ˆæœ¬")
            return results
        
        # ä¸ºå…¶ä»–è¯­è¨€ç”Ÿæˆç¿»è¯‘ç‰ˆæœ¬
        for lang_code in language_codes:
            if lang_code == primary_lang:
                continue  # è·³è¿‡ä¸»è¯­è¨€ï¼Œå·²ç»ç”Ÿæˆäº†
                
            print(f"    æ­£åœ¨ç”Ÿæˆç¿»è¯‘ç‰ˆæœ¬ {LANGUAGES[lang_code]}...")
            
            # æ·»åŠ å»¶è¿Ÿé¿å…ç¿»è¯‘APIé™åˆ¶
            import time
            time.sleep(1)
            
            # ä½¿ç”¨å…±äº«å›¾ç‰‡æ¨¡å¼ç”Ÿæˆç¿»è¯‘æ–‡ç« 
            file_path, error, usage_record = self.article_generator.generate_translated_markdown_with_shared_images(
                keyword, need_images, lang_code, primary_content, shared_image_data, False, repo_name
            )
            
            results[lang_code] = {
                'file': file_path,
                'error': error,
                'language': LANGUAGES[lang_code],
                'usage_record': usage_record
            }
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            if lang_code != language_codes[-1]:
                time.sleep(1)
        
        return results
    
    def upload_to_specific_repository(self, results, repo_id, repo_config, is_final_commit=False):
        """ä¸Šä¼ æ–‡ç« åˆ°æŒ‡å®šä»“åº“ï¼ˆæ¯ä¸ªè¯­è¨€ç‰ˆæœ¬åˆ†åˆ«ä¸Šä¼ ï¼‰"""
        upload_results = []
        
        # æ”¶é›†æ‰€æœ‰æˆåŠŸçš„è¯­è¨€ç‰ˆæœ¬
        successful_results = []
        for lang_code, result in results.items():
            if result['error'] or not result['file']:
                continue
            successful_results.append((lang_code, result))
        
        if not successful_results:
            print(f"     âŒ æ²¡æœ‰æˆåŠŸçš„è¯­è¨€ç‰ˆæœ¬å¯ä»¥ä¸Šä¼ ")
            return upload_results
        
        if is_final_commit:
            print(f"     ğŸ“¤ ä¸Šä¼ æ‰€æœ‰è¯­è¨€ç‰ˆæœ¬åˆ° {repo_config['name']} (æœ€åä¸€æ¬¡æäº¤ï¼Œå°†è§¦å‘è‡ªåŠ¨éƒ¨ç½²)...")
        else:
            print(f"     ğŸ“¤ ä¸Šä¼ æ‰€æœ‰è¯­è¨€ç‰ˆæœ¬åˆ° {repo_config['name']} (æ™®é€šæäº¤ï¼Œè·³è¿‡è‡ªåŠ¨éƒ¨ç½²)...")
        
        # æ˜¾ç¤ºè¦ä¸Šä¼ çš„è¯­è¨€ç‰ˆæœ¬
        lang_names = [result['language'] for _, result in successful_results]
        print(f"     ğŸ“ åŒ…å«è¯­è¨€ç‰ˆæœ¬: {', '.join(lang_names)}")
        
        # ä¸ºæ¯ä¸ªè¯­è¨€ç‰ˆæœ¬åˆ†åˆ«ä¸Šä¼ ï¼ˆä½†ä½¿ç”¨ç›¸åŒçš„is_final_commitçŠ¶æ€ï¼‰
        for i, (lang_code, result) in enumerate(successful_results):
            # åªæœ‰æœ€åä¸€ä¸ªè¯­è¨€ç‰ˆæœ¬æ‰è§¦å‘è‡ªåŠ¨éƒ¨ç½²
            current_is_final_commit = is_final_commit and (i == len(successful_results) - 1)
            
            # å‡†å¤‡æ–‡ç« ä¿¡æ¯
            article_info = {
                'title': 'Daily Publish Article',
                'keyword': 'Daily Publish',
                'game_name': '',
                'custom_suffix': '',
                'language': lang_code,
                'folder_name': Path(result['file']).name,
                'need_images': True,
                'file_path': result['file'],
                'image_dir': str(Path(result['file']) / 'images')
            }
            
            if current_is_final_commit:
                print(f"     ğŸ“¤ ä¸Šä¼  {result['language']} ç‰ˆæœ¬åˆ° {repo_config['name']} (æœ€åä¸€æ¬¡æäº¤ï¼Œå°†è§¦å‘è‡ªåŠ¨éƒ¨ç½²)...")
            else:
                print(f"     ğŸ“¤ ä¸Šä¼  {result['language']} ç‰ˆæœ¬åˆ° {repo_config['name']} (æ™®é€šæäº¤ï¼Œè·³è¿‡è‡ªåŠ¨éƒ¨ç½²)...")
            
            # ä¸Šä¼ åˆ°æŒ‡å®šGitä»“åº“
            upload_result = self.article_generator.repo_manager.upload_to_git_repository(
                result['file'], repo_config, article_info, repo_id, current_is_final_commit
            )
            
            upload_results.append(upload_result)
            
            if upload_result['success']:
                if current_is_final_commit:
                    print(f"     âœ… ä¸Šä¼ åˆ° {repo_config['name']} æˆåŠŸ (å·²è§¦å‘è‡ªåŠ¨éƒ¨ç½²)")
                else:
                    print(f"     âœ… ä¸Šä¼ åˆ° {repo_config['name']} æˆåŠŸ (è·³è¿‡è‡ªåŠ¨éƒ¨ç½²)")
            else:
                print(f"     âŒ ä¸Šä¼ åˆ° {repo_config['name']} å¤±è´¥: {upload_result['error']}")
        
        return upload_results
    
    def save_to_kv(self, kv_key, processed_data):
        """ä¿å­˜æ•°æ®åˆ°KVå­˜å‚¨"""
        try:
            kv_write(self.account_id, self.namespace_id, self.api_token, kv_key, 
                    json.dumps(processed_data, ensure_ascii=False, indent=2))
            print(f"    ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°KVå­˜å‚¨")
        except Exception as e:
            print(f"    âŒ ä¿å­˜åˆ°KVå­˜å‚¨å¤±è´¥: {str(e)}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ¯æ—¥æ–‡ç« å‘å¸ƒç®¡ç†å™¨')
    parser.add_argument('--images', type=bool, default=True, help='æ˜¯å¦éœ€è¦ä¸‹è½½å›¾ç‰‡')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å‘å¸ƒç®¡ç†å™¨
    publish_manager = PublishManager()
    
    if args.test:
        print("ğŸ§ª å¯åŠ¨æµ‹è¯•æ¨¡å¼...")
        # æµ‹è¯•æ¨¡å¼ï¼šå‡å°‘å‘å¸ƒæ•°é‡
        publish_manager.articles_per_site = 2
        publish_manager.total_sites = 2
    
    # æ‰§è¡Œæ¯æ—¥å‘å¸ƒ
    success = publish_manager.publish_daily_articles(need_images=args.images)
    
    if success:
        print("âœ… æ¯æ—¥å‘å¸ƒä»»åŠ¡å®Œæˆ")
    else:
        print("âŒ æ¯æ—¥å‘å¸ƒä»»åŠ¡å¤±è´¥")

if __name__ == "__main__":
    main()
